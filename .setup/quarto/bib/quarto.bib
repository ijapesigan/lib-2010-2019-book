@Book{Bolger-Laurenceau-2013,
  author = {Niall Bolger and Jean-Philippe Laurenceau},
  date = {2013},
  title = {Intensive longitudinal methods: An introduction to diary and experience sampling research},
  isbn = {9781462506927},
  publisher = {Guilford Publications},
  abstract = {A complete, practical guide to planning and executing an intensive longitudinal study, this book provides the tools for understanding within-subject social, psychological, and physiological processes in everyday contexts. Intensive longitudinal studies involve many repeated measurements taken on individuals, dyads, or groups, and include diary and experience sampling studies. A range of engaging, worked-through research examples with datasets are featured. Coverage includes how to: select the best intensive longitudinal design for a particular research question, model within-subject change processes for continuous and categorical outcomes, distinguish within-subject from between-subjects effects, assess the reliability of within-subject changes, assure sufficient statistical power, and more. Several end-of-chapter write-ups illustrate effective ways to present study findings for publication.},
}

@Book{Cheung-2015,
  author = {Mike W.-L. Cheung},
  date = {2015-04},
  title = {Meta‐analysis: A structural equation modeling approach},
  doi = {10.1002/9781118957813},
  isbn = {9781118957813},
  publisher = {Wiley},
  abstract = {Presents a novel approach to conducting meta-analysis using structural equation modeling. Structural equation modeling (SEM) and meta-analysis are two powerful statistical methods in the educational, social, behavioral, and medical sciences. They are often treated as two unrelated topics in the literature. This book presents a unified framework on analyzing meta-analytic data within the SEM framework, and illustrates how to conduct meta-analysis using the metaSEM package in the R statistical environment. Meta-Analysis: A Structural Equation Modeling Approach begins by introducing the importance of SEM and meta-analysis in answering research questions. Key ideas in meta-analysis and SEM are briefly reviewed, and various meta-analytic models are then introduced and linked to the SEM framework. Fixed-, random-, and mixed-effects models in univariate and multivariate meta-analyses, three-level meta-analysis, and meta-analytic structural equation modeling, are introduced. Advanced topics, such as using restricted maximum likelihood estimation method and handling missing covariates, are also covered. Readers will learn a single framework to apply both meta-analysis and SEM. Examples in R and in Mplus are included. This book will be a valuable resource for statistical and academic researchers and graduate students carrying out meta-analyses, and will also be useful to researchers and statisticians using SEM in biostatistics. Basic knowledge of either SEM or meta-analysis will be helpful in understanding the materials in this book.},
}

@InBook{Deboeck-Preacher-Cole-2018,
  author = {Pascal R. Deboeck and Kristopher J. Preacher and David A. Cole},
  booktitle = {Continuous time modeling in the behavioral and related sciences},
  date = {2018},
  title = {Mediation modeling: Differing perspectives on time alter mediation inferences},
  doi = {10.1007/978-3-319-77219-6_8},
  isbn = {9783319772196},
  pages = {179--203},
  publisher = {Springer International Publishing},
  abstract = {Time is unlike any other variable collected in the social, behavioral, and medical sciences. Research participants who are sampled, and variables that are measured, come in distinct, discrete units. Although time is often recorded in such discrete units (e.g., wave 1, grade 3, day 5), time is markedly different from either participants or variables. Sampling time points is unlike sampling people or variables, as there are an arbitrary number of additional samples that can be collected between any two occasions of measurement. These interstitial samples are ignored by many longitudinal modeling paradigms. These observations that occur between sampling occasions form the basis for the perspectives on mediation explored in this chapter. We focus on the difference in perspectives offered by discrete time approaches commonly utilized in mediation research versus models that conceptualize time as a continuous variable. The differences in how one conceptualizes time have the potential to alter such core mediation concepts as direct and indirect effect, complete and partial mediation, and even what constitutes a ``mediation'' model.},
}

@Book{Eddelbuettel-2013,
  author = {Dirk Eddelbuettel},
  date = {2013},
  title = {Seamless {R} and {C++} integration with {Rcpp}},
  doi = {10.1007/978-1-4614-6868-4},
  isbn = {978-1-4614-6868-4},
  publisher = {Springer New York},
  abstract = {Illustrates a range of statistical computations in R using the Rcpp package.  Provides a general introduction to extending R with C++ code. Features an appendix for R users new to the C++ programming language Rcpp packages are presented in the context of useful application case studies.},
  annotation = {r, r-packages},
}

@Book{Enders-2010,
  author = {Craig K. Enders},
  date = {2010-05-31},
  title = {Applied missing data analysis},
  isbn = {9781606236390},
  pagetotal = {377},
  library = {HA29 .E497 2010},
  addendum = {https://lccn.loc.gov/2010008465},
  abstract = {Walking readers step by step through complex concepts, this book translates missing data techniques into something that applied researchers and graduate students can understand and utilize in their own research. Enders explains the rationale and procedural details for maximum likelihood estimation, Bayesian estimation, multiple imputation, and models for handling missing not at random (MNAR) data. Easy-to-follow examples and small simulated data sets illustrate the techniques and clarify the underlying principles. The companion website (www.appliedmissingdata.com) includes data files and syntax for the examples in the book as well as up-to-date information on software. The book is accessible to substantive researchers while providing a level of detail that will satisfy quantitative specialists.},
  publisher = {Guilford Publications},
  keywords = {Social sciences--Statistical methods, Missing observations (Statistics), Social sciences--Research--Methodology},
}

@Book{Flor-Turk-2011,
  author = {Herta Flor and Dennis C. Turk},
  date = {2011},
  title = {Chronic pain: An integrated biobehavioral approach},
  isbn = {978-0-931092-90-9},
  location = {Seattle, WA},
  publisher = {IASP Press},
  abstract = {This volume provides a psychobiological perspective on people who experience chronic pain and describes a comprehensive approach to their treatment. The text focuses on the interaction of psychosocial (psychological, behavioral, and social) and physiological processes in people with chronic pain and the implications that follow. Our basic hypothesis is that chronic pain is a learned response, whereby ``pain memories'' rather than current nociceptive input determine much of the pain experienced. Moreover, interdisciplinary approaches that integrate psychological principles and approaches with traditional biomedical knowledge in the assessment and treatment of people with chronic pain are more fruitful than any single modalities, be they physical (surgery, medication, regional anesthesia, or neuroaugmentive interventions) or psychological (biofeedback, counseling, or psychotherapy). Although our emphasis is on the role of psychological and social factors in chronic pain states, we attempt to integrate these aspects with the current biological understanding of the neurophysiology of nociception.},
}

@InBook{Koopman-Howe-Hollenbeck-2014,
  author = {Joel Koopman and Michael Howe and John R. Hollenbeck},
  booktitle = {More statistical and methodological myths and urban legends: Doctrine, verity and fable in organizational and social sciences},
  date = {2014},
  title = {Pulling the {Sobel} test up by its bootstraps},
  bookauthor = {Charles E. Lance and Robert J. Vandenberg},
  isbn = {9780203775851},
  pages = {224--243},
  doi = {10.4324/9780203775851},
  isbn = {9780203775851},
  abstract = {In the domain of building and testing theory, mediation relationships are among the most important that can be proposed. Mediation helps to explicate our theoretical models (Leavitt, Mitchell, \& Peterson, 2010) and addresses the fundamental question of why two constructs are related (Whetten, 1989). One of the better-known methods for testing mediation is commonly referred to as the ``Sobel test,'' named for the researcher who derived a standard error (Sobel, 1982) to test the significance of the indirect effect. Recently, a number of different research teams (e.g., Preacher \& Hayes, 2004; Shrout \& Bolger, 2002) have criticized the Sobel test because this standard error requires an assumption of normality for the indirect effect sampling distribution. This distribution tends to be positively skewed (i.e,. not normal), particularly in small samples, and so this assumption can be problematic (Preacher \& Hayes, 2004; Stone \& Sobel, 1990). As a result, the statistical power of the Sobel test may be lessened in these contexts (Preacher \& Hayes 2004; Shrout \& Bolger, 2002). In light of this concern, some scholars have advocated instead for the use of bootstrapping to test the significance of the indirect effect (e.g.. Shrout \& Bolger 2002). Bootstrapping requires no a priori assumption about the shape of the sampling distribution because this distribution is empirically estimated using a resampling procedure (Efron \& Tibshirani, 1993). As a result, departures from normality are less troublesome when creating a confidence interval for the indirect effect. For this reason, bootstrapping is now widely believed to be inherently superior to the Sobel test when testing the significance of the indirect effect in organizational research. Our position is that this belief constitutes an urban legend. As with all statistical urban legends, there is an underlying kernel of truth to the belief that bootstrapping is superior to the Sobel test. However, as we discuss in this chapter, there are several reasons to be concerned with a broad belief in the superiority of bootstrapping. We begin with a brief overview of mediation testing focusing on the Sobel test and bootstrapping and then explain the underlying kernel of truth that has propelled bootstrapping to the forefront of mediation testing in organizational research. Subsequently, we discuss four areas of concern that cast doubt on the belief of the inherent superiority of bootstrapping. Finally, we conclude with recommendations concerning the future of mediation testing in organizational research.},
  publisher = {Routledge/Taylor \& Francis Group},
  annotation = {mediation, mediation-delta, mediation-bootstrap},
}

@InBook{Kreiss-Lahiri-2012,
  author = {Jens-Peter Kreiss and Soumendra Nath Lahiri},
  booktitle = {Time series analysis: Methods and applications},
  date = {2012},
  title = {Bootstrap methods for time series},
  doi = {10.1016/b978-0-444-53858-1.00001-6},
  isbn = {9780444538581},
  pages = {3--26},
  abstract = {The chapter gives a review of the literature on bootstrap methods for time series data. It describes various possibilities on how the bootstrap method, initially introduced for independent random variables, can be extended to a wide range of dependent variables in discrete time, including parametric or nonparametric time series models, autoregressive and Markov processes, long range dependent time series and nonlinear time series, among others. Relevant bootstrap approaches, namely the intuitive residual bootstrap and Markovian bootstrap methods, the prominent block bootstrap methods as well as frequency domain resampling procedures, are described. Further, conditions for consistent approximations of distributions of parameters of interest by these methods are presented. The presentation is deliberately kept non-technical in order to allow for an easy understanding of the topic, indicating which bootstrap scheme is advantageous under a specific dependence situation and for a given class of parameters of interest. Moreover, the chapter contains an extensive list of relevant references for bootstrap methods for time series.},
  keywords = {bootstrap methods, discrete Fourier transform, linear and nonlinear time series, long range dependence, Markov chains, resampling, second order correctness, stochastic processes},
  publisher = {Elsevier},
  issn = {0169-7161},
}

@Book{Little-Rubin-2019,
  author = {Roderick J. A. Little and Donald B. Rubin},
  date = {2019-04},
  title = {Statistical analysis with missing data},
  doi = {10.1002/9781119482260},
  edition = {3},
  isbn = {9781119482260},
  library = {QA276},
  addendum = {https://lccn.loc.gov/2018061330},
  abstract = {An up-to-date, comprehensive treatment of a classic text on missing data in statistics.
  The topic of missing data has gained considerable attention in recent decades. This new edition by two acknowledged experts on the subject offers an up-to-date account of practical methodology for handling missing data problems. Blending theory and application, authors Roderick Little and Donald Rubin review historical approaches to the subject and describe simple methods for multivariate analysis with missing values. They then provide a coherent theory for analysis of problems based on likelihoods derived from statistical models for the data and the missing data mechanism, and then they apply the theory to a wide range of important missing data problems.
  Statistical Analysis with Missing Data, Third Edition starts by introducing readers to the subject and approaches toward solving it. It looks at the patterns and mechanisms that create the missing data, as well as a taxonomy of missing data. It then goes on to examine missing data in experiments, before discussing complete-case and available-case analysis, including weighting methods. The new edition expands its coverage to include recent work on topics such as nonresponse in sample surveys, causal inference, diagnostic methods, and sensitivity analysis, among a host of other topics.
  \begin{itemize} \item An updated ``classic'' written by renowned authorities on the subject \item Features over 150 exercises (including many new ones) \item Covers recent work on important methods like multiple imputation, robust alternatives to weighting, and Bayesian methods \item Revises previous topics based on past student feedback and class experience \item Contains an updated and expanded bibliography \end{itemize}
  The authors were awarded The Karl Pearson Prize in 2017 by the International Statistical Institute, for a research contribution that has had profound influence on statistical theory, methodology or applications. Their work ``has been no less than defining and transforming.'' (ISI)
  Statistical Analysis with Missing Data, Third Edition is an ideal textbook for upper undergraduate and/or beginning graduate level students of the subject. It is also an excellent source of information for applied statisticians and practitioners in government and industry.},
  publisher = {Wiley},
  keywords = {Mathematical statistics, Mathematical statistics--Problems, exercises, etc., Missing observations (Statistics), Missing observations (Statistics)--Problems, exercises, etc.},
}

@Book{Mehl-Conner-Csikszentmihalyi-2011,
  author = {Matthias R. Mehl and Tamlin S. Conner and Mihaly. Csikszentmihalyi},
  date = {2011},
  title = {Handbook of research methods for studying daily life},
  isbn = {9781609187491},
  publisher = {Guilford Publications},
  abstract = {Laboratory-based experimental methods historically have been the strength and pride of psychology and related disciplines. Yet a comprehensive science of behavior also requires the study of humans in real life. Bringing together leading investigators, this book reviews the breadth of current approaches for studying how people think, feel, and behave in everyday environments. The Handbook is organized in four parts. Part I covers the theoretical and methodological foundations of conducting daily life research. Part II provides guidance for designing a high-quality study and selecting and implementing appropriate methods. The chapters describe experience sampling methods, diary methods, ambulatory physiological measures, and other tools---including recording technologies and computerized approaches---that allow repeated, real-time measurement in natural settings. Part III focuses on techniques for analyzing intensive data from daily life, featuring practical discussions of power analysis, psychometrics, data cleaning, multilevel modeling, time series analysis, and other topics. Part IV reviews how methods for studying daily life have been employed in different subfields and research areas, such as the study of emotion, close relationships, personality, health, development, psychopathology, and mental health treatment. Specific advantages and challenges inherent to using the methods in each area are discussed. Timely and authoritative, this handbook meets a key need for research psychologists and for graduate students in social/personality, health, developmental, industrial/organizational, and clinical psychology.},
}

@Book{Millsap-2011,
  author = {Roger E. Millsap},
  date = {2011},
  title = {Statistical approaches to measurement invariance},
  isbn = {9780203821961 },
  doi = {10.4324/9780203821961},
  publisher = {Routledge},
}

@InBook{Oravecz-Wood-Ram-2018,
  author = {Zita Oravecz and Julie Wood and Nilam Ram},
  booktitle = {Continuous time modeling in the behavioral and related sciences},
  date = {2018},
  title = {On fitting a continuous-time stochastic process model in the {Bayesian} framework},
  doi = {10.1007/978-3-319-77219-6_3},
  isbn = {9783319772196},
  pages = {55--78},
  publisher = {Springer International Publishing},
  abstract = {Process models can be viewed as mathematical tools that allow researchers to formulate and test theories on the data-generating mechanism underlying observed data. In this chapter we highlight the advantages of this approach by proposing a multilevel, continuous-time stochastic process model to capture the dynamical homeostatic process that underlies observed intensive longitudinal data. Within the multilevel framework, we also link the dynamical processes parameters to time-varying and time-invariant covariates. However, estimating all model parameters (e.g., process model parameters and regression coefficients) simultaneously requires custom-made implementation of the parameter estimation; therefore we advocate the use of a Bayesian statistical framework for fitting these complex process models. We illustrate application to data on self-reported affective states collected in an ecological momentary assessment setting.},
}

@InBook{Oud-Delsing-2010,
  author = {Johan H. L. Oud and Marc J. M. H. Delsing},
  editor = {Kees {van Montfort} and Johan H. L. Oud and A. Satorra},
  booktitle = {Longitudinal research with latent variables},
  date = {2010},
  title = {Continuous time modeling of panel data by means of {SEM}},
  doi = {10.1007/978-3-642-11760-2_7},
  isbn = {9783642117602},
  pages = {201--244},
  publisher = {Springer Berlin Heidelberg},
  abstract = {After a brief history of continuous time modeling and its implementation in panel analysis by means of structural equation modeling (SEM), the problems of discrete time modeling are discussed in detail. This is done by means of the popular cross-lagged panel design. Next, the exact discrete model (EDM) is introduced, which accounts for the exact nonlinear relationship between the underlying continuous time model and the resulting discrete time model for data analysis. In addition, a linear approximation of the EDM is discussed: the approximate discrete model (ADM). It is recommended to apply the ADM-SEM procedure by means of a SEM program such as LISREL in the model building phase and the EDM-SEM procedure by means of Mx in the final model estimation phase. Both procedures are illustrated in detail by two empirical examples: Externalizing and Internalizing Problem Behavior in children; Individualism, Nationalism and Ethnocentrism in the Flemish electorate.},
}

@Book{Pawitan-2013,
  author = {Yudi Pawitan},
  date = {2013-01-17},
  title = {In all likelihood: Statistical modelling and inference using likelihood},
  isbn = {9780199671229},
  pagetotal = {544},
  abstract = {Based on a course in the theory of statistics this text concentrates on what can be achieved using the likelihood/Fisherian method of taking account of uncertainty when studying a statistical problem. It takes the concept ot the likelihood as providing the best methods for unifying the demands of statistical modelling and the theory of inference. Every likelihood concept is illustrated by realistic examples, which are not compromised by computational problems. Examples range from a simile comparison of two accident rates, to complex studies that require generalised linear or semiparametric modelling.
  The emphasis is that the likelihood is not simply a device to produce an estimate, but an important tool for modelling. The book generally takes an informal approach, where most important results are established using heuristic arguments and motivated with realistic examples. With the currently available computing power, examples are not contrived to allow a closed analytical solution, and the book can concentrate on the statistical aspects of the data modelling. In addition to classical likelihood theory, the book covers many modern topics such as generalized linear models and mixed models, non parametric smoothing, robustness, the EM algorithm and empirical likelihood.},
  publisher = {Oxford University Press},
}

@InBook{Ryan-Kuiper-Hamaker-2018,
  author = {Oisin Ryan and Rebecca M. Kuiper and Ellen L. Hamaker},
  booktitle = {Continuous time modeling in the behavioral and related sciences},
  date = {2018},
  title = {A continuous-time approach to intensive longitudinal data: What, why, and how?},
  doi = {10.1007/978-3-319-77219-6_2},
  isbn = {9783319772196},
  pages = {27--54},
  publisher = {Springer International Publishing},
  abstract = {The aim of this chapter is to (a) provide a broad didactical treatment of the first-order stochastic differential equation model—also known as the continuous-time (CT) first-order vector autoregressive (VAR(1)) model—and (b) argue for and illustrate the potential of this model for the study of psychological processes using intensive longitudinal data. We begin by describing what the CT-VAR(1) model is and how it relates to the more commonly used discrete-time VAR(1) model. Assuming no prior knowledge on the part of the reader, we introduce important concepts for the analysis of dynamic systems, such as stability and fixed points. In addition we examine why applied researchers should take a continuous-time approach to psychological phenomena, focusing on both the practical and conceptual benefits of this approach. Finally, we elucidate how researchers can interpret CT models, describing the direct interpretation of CT model parameters as well as tools such as impulse response functions, vector fields, and lagged parameter plots. To illustrate this methodology, we reanalyze a single-subject experience-sampling dataset with the R package ctsem; for didactical purposes, R code for this analysis is included, and the dataset itself is publicly available.},
}

@Book{Shumway-Stoffer-2017,
  author = {Robert H. Shumway and David S. Stoffer},
  publisher = {Springer International Publishing},
  title = {Time series analysis and its applications: With {R} examples},
  isbn = {978-3-319-52452-8},
  date = {2017},
  doi = {10.1007/978-3-319-52452-8},
  library = {QA280},
  addendum = {https://lccn.loc.gov/2019301243},
  abstract = {The fourth edition of this popular graduate textbook, like its predecessors, presents a balanced and comprehensive treatment of both time and frequency domain methods with accompanying theory. Numerous examples using nontrivial data illustrate solutions to problems such as discovering natural and anthropogenic climate change, evaluating pain perception experiments using functional magnetic resonance imaging, and monitoring a nuclear test ban treaty.
The book is designed as a textbook for graduate level students in the physical, biological, and social sciences and as a graduate level text in statistics. Some parts may also serve as an undergraduate introductory course. Theory and methodology are separated to allow presentations on different levels. In addition to coverage of classical methods of time series regression, ARIMA models, spectral analysis and state-space models, the text includes modern developments including categorical time series analysis, multivariate spectral methods, long memory series, nonlinear models, resampling techniques, GARCH models, ARMAX models, stochastic volatility, wavelets, and Markov chain Monte Carlo integration methods.
This edition includes R code for each numerical example in addition to Appendix R, which provides a reference for the data sets and R scripts used in the text in addition to a tutorial on basic R commands and R time series. An additional file is available on the book’s website for download, making all the data sets and scripts easy to load into R.},
  keywords = {Time-series analysis, Time-series analysis--Data processing, R (Computer program language)},
}

@InBook{Turk-Monarch-2018,
  author = {Dennis C. Turk and Elena S. Monarch},
  booktitle = {Psychological approaches to pain management: A practitioner's handbook},
  date = {2018},
  title = {Biopsychosocial perspective on chronic pain},
  edition = {3},
  editor = {Dennis C. Turk and Robert J. Gatchel},
  isbn = {9781462535620},
  location = {New York},
  publisher = {The Guilford Press},
}

@Book{vanBuuren-2018,
  author = {Stef {van Buuren}},
  date = {2018-07},
  title = {Flexible imputation of missing data},
  doi = {10.1201/9780429492259},
  edition = {2},
  isbn = {9780429492259},
  publisher = {Chapman and Hall/{CRC}},
  library = {QA278},
  addendum = {https://lccn.loc.gov/2019719619},
  abstract = {Missing data pose challenges to real-life data analysis. Simple ad-hoc fixes, like deletion or mean imputation, only work under highly restrictive conditions, which are often not met in practice. Multiple imputation replaces each missing value by multiple plausible values. The variability between these replacements reflects our ignorance of the true (but missing) value. Each of the completed data set is then analyzed by standard methods, and the results are pooled to obtain unbiased estimates with correct confidence intervals. Multiple imputation is a general approach that also inspires novel solutions to old problems by reformulating the task at hand as a missing-data problem.
  This is the second edition of a popular book on multiple imputation, focused on explaining the application of methods through detailed worked examples using the MICE package as developed by the author. This new edition incorporates the recent developments in this fast-moving field.
  This class-tested book avoids mathematical and technical details as much as possible: formulas are accompanied by verbal statements that explain the formula in accessible terms. The book sharpens the reader’s intuition on how to think about missing data, and provides all the tools needed to execute a well-grounded quantitative analysis in the presence of missing data.},
  keywords = {Multivariate analysis, Multiple imputation (Statistics), Missing observations (Statistics)},
}

@Book{vanMontfort-Oud-Satorra-2010,
  date = {2010},
  title = {Longitudinal research with latent variables},
  editor = {Kees {van Montfort} and Johan H. L. Oud and A. Satorra},
  isbn = {9783642117602},
  location = {New York},
  note = {Includes bibliographical references.},
  pagetotal = {301},
  publisher = {Springer},
  ppn_gvk = {1772810835},
}

@Book{vanMontfort-Oud-Voelkle-2018,
  date = {2018},
  title = {Continuous time modeling in the behavioral and related sciences},
  doi = {10.1007/978-3-319-77219-6},
  editor = {Kees {van Montfort} and Johan H. L. Oud and Manuel C. Voelkle},
  publisher = {Springer International Publishing},
}

@InCollection{Zhang-Wang-Tong-2015,
  author = {Zhiyong Zhang and Lijuan Wang and Xin Tong},
  booktitle = {Quantitative Psychology Research},
  date = {2015},
  title = {Mediation analysis with missing data through multiple imputation and bootstrap},
  doi = {10.1007/978-3-319-19977-1_24},
  pages = {341--355},
  abtract = {A method using multiple imputation and bootstrap for dealing with missing data in mediation analysis is introduced and implemented in both SAS and R. Through simulation studies, it is shown that the method performs well for both MCAR and MAR data without and with auxiliary variables. It is also shown that the method can work for MNAR data if auxiliary variables related to missingness are included. The application of the method is demonstrated through the analysis of a subset of data from the National Longitudinal Survey of Youth. Mediation analysis with missing data can be conducted using the provided SAS macros and R package bmem.},
  publisher = {Springer International Publishing},
  keywords = {mediation analysis, missing data, multiple imputation, bootstrap},
  annotation = {mediation, mediation-missing, mediation-bootstrap},
}
